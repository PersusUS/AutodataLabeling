"""
AutoDataLabelingPipeline: Clase principal que orquesta todo el proceso de etiquetado autom√°tico.
"""

from typing import Optional, List, Dict, Any
from pathlib import Path
import time
from ..models import Dataset, Image, Cluster
from .dataset_loader import DatasetLoader
from .embedding_generator import EmbeddingGenerator
from .hierarchical_clusterer import HierarchicalClusterer
from .image_selector import ImageSelector
from .clip_labeler import CLIPLabeler
from .image_classifier import ImageClassifier


class AutoDataLabelingPipeline:
    """
    Pipeline principal para el etiquetado autom√°tico de im√°genes.
    
    Integra todos los componentes del sistema: carga de datos, generaci√≥n de embeddings,
    clustering, selecci√≥n de representativas, etiquetado con CLIP y clasificaci√≥n.
    """
    
    def __init__(self,
                 embedding_model_size: str = "base",
                 num_representatives: int = 3,
                 clip_model: str = "ViT-B/32",
                 clustering_linkage: str = "ward",
                 device: str = "auto"):
        """
        Inicializa el pipeline de etiquetado autom√°tico.
        
        Args:
            embedding_model_size: Tama√±o del modelo DINOv2 ("small", "base", "large", "giant")
            num_representatives: N√∫mero de im√°genes representativas por cluster
            clip_model: Modelo CLIP a usar para etiquetado
            clustering_linkage: M√©todo de enlace para clustering jer√°rquico
            device: Dispositivo a usar ("cpu", "cuda", "auto")
        """
        # Inicializar componentes
        self.dataset_loader = DatasetLoader()
        self.embedding_generator = EmbeddingGenerator(
            model_size=embedding_model_size,
            device=device
        )
        self.clusterer = HierarchicalClusterer(
            linkage=clustering_linkage,
            min_cluster_size=3
        )
        self.image_selector = ImageSelector(
            num_representatives=num_representatives
        )
        self.clip_labeler = CLIPLabeler(
            model_name=clip_model,
            device=device
        )
        self.classifier = ImageClassifier()
        
        # Estado del pipeline
        self.current_dataset: Optional[Dataset] = None
        self.trained_clusters: List[Cluster] = []
        self.is_trained = False
        
        # Estad√≠sticas de ejecuci√≥n
        self.execution_stats = {
            'total_time': 0.0,
            'embedding_time': 0.0,
            'clustering_time': 0.0,
            'labeling_time': 0.0,
            'images_processed': 0,
            'clusters_created': 0
        }
    
    def train_pipeline(self, dataset_path: Path, dataset_name: Optional[str] = None) -> Dataset:
        """
        Entrena el pipeline completo con un dataset de im√°genes.
        
        Args:
            dataset_path: Ruta al directorio con im√°genes de entrenamiento
            dataset_name: Nombre del dataset (opcional)
            
        Returns:
            Dataset procesado con clusters etiquetados
            
        Raises:
            FileNotFoundError: Si el directorio no existe
            ValueError: Si no hay im√°genes v√°lidas
        """
        start_time = time.time()
        print(f"Iniciando entrenamiento del pipeline con dataset: {dataset_path}")
        
        try:
            # Paso 1: Cargar dataset
            print("üìÅ Cargando dataset...")
            self.current_dataset = self.dataset_loader.load_dataset_recursive(
                dataset_path, dataset_name
            )
            print(f"‚úÖ Dataset cargado: {len(self.current_dataset.images)} im√°genes")
            
            # Paso 2: Generar embeddings
            print("üß† Generando embeddings con DINOv2...")
            embedding_start = time.time()
            self.current_dataset = self.embedding_generator.generate_dataset_embeddings(
                self.current_dataset
            )
            self.execution_stats['embedding_time'] = time.time() - embedding_start
            print(f"‚úÖ Embeddings generados para {len(self.current_dataset.images)} im√°genes")
            
            # Paso 3: Clustering jer√°rquico
            print("üéØ Aplicando clustering jer√°rquico...")
            clustering_start = time.time()
            self.trained_clusters = self.clusterer.create_clusters_from_dataset(
                self.current_dataset
            )
            self.execution_stats['clustering_time'] = time.time() - clustering_start
            print(f"‚úÖ Creados {len(self.trained_clusters)} clusters")
            
            # Paso 4: Seleccionar im√°genes representativas
            print("üé≠ Seleccionando im√°genes representativas...")
            for cluster in self.trained_clusters:
                self.image_selector.select_representative_images(cluster)
            print(f"‚úÖ Representativas seleccionadas para {len(self.trained_clusters)} clusters")
            
            # Paso 5: Etiquetar clusters con CLIP
            print("üè∑Ô∏è Etiquetando clusters con CLIP...")
            labeling_start = time.time()
            cluster_labels = self.clip_labeler.label_clusters(self.trained_clusters)
            self.execution_stats['labeling_time'] = time.time() - labeling_start
            print(f"‚úÖ Etiquetados {len(cluster_labels)} clusters")
            
            # Paso 6: Entrenar clasificador
            print("ü§ñ Entrenando clasificador...")
            self.classifier.train(self.trained_clusters)
            self.is_trained = True
            print("‚úÖ Clasificador entrenado")
            
            # Actualizar estad√≠sticas
            total_time = time.time() - start_time
            self.execution_stats.update({
                'total_time': total_time,
                'images_processed': len(self.current_dataset.images),
                'clusters_created': len(self.trained_clusters)
            })
            
            print(f"üéâ Pipeline entrenado exitosamente en {total_time:.2f} segundos")
            return self.current_dataset
            
        except Exception as e:
            print(f"‚ùå Error durante el entrenamiento: {e}")
            raise
    
    def classify_new_images(self, images_path: Path) -> List[Dict[str, Any]]:
        """
        Clasifica nuevas im√°genes usando el pipeline entrenado.
        
        Args:
            images_path: Ruta con nuevas im√°genes a clasificar
            
        Returns:
            Lista de diccionarios con resultados de clasificaci√≥n
            
        Raises:
            RuntimeError: Si el pipeline no ha sido entrenado
        """
        if not self.is_trained:
            raise RuntimeError("El pipeline debe ser entrenado antes de clasificar im√°genes")
        
        print(f"üîç Clasificando nuevas im√°genes desde: {images_path}")
        
        # Cargar nuevas im√°genes
        new_dataset = self.dataset_loader.load_dataset_recursive(images_path, "new_images")
        print(f"üìÅ Cargadas {len(new_dataset.images)} nuevas im√°genes")
        
        # Generar embeddings para las nuevas im√°genes
        print("üß† Generando embeddings para nuevas im√°genes...")
        new_dataset = self.embedding_generator.generate_dataset_embeddings(new_dataset)
        
        # Clasificar cada imagen
        print("üéØ Clasificando im√°genes...")
        results = []
        for image in new_dataset.images:
            try:
                label = self.classifier.predict(image)
                probabilities = self.classifier.get_cluster_probabilities(image)
                
                result = {
                    'image_path': str(image.path),
                    'image_name': image.name,
                    'predicted_label': label.name,
                    'confidence': label.confidence,
                    'source': label.source,
                    'cluster_probabilities': probabilities,
                    'metadata': label.metadata
                }
                results.append(result)
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error clasificando {image.name}: {e}")
                results.append({
                    'image_path': str(image.path),
                    'image_name': image.name,
                    'predicted_label': 'error',
                    'confidence': 0.0,
                    'error': str(e)
                })
        
        print(f"‚úÖ Clasificadas {len(results)} im√°genes")
        return results
    
    def classify_single_image(self, image_path: Path) -> Dict[str, Any]:
        """
        Clasifica una sola imagen.
        
        Args:
            image_path: Ruta de la imagen a clasificar
            
        Returns:
            Diccionario con resultado de clasificaci√≥n
        """
        if not self.is_trained:
            raise RuntimeError("El pipeline debe ser entrenado antes de clasificar")
        
        # Crear imagen temporal
        image = Image(
            path=image_path,
            id="temp_image",
            name=image_path.name
        )
        
        # Generar embedding
        embedding_obj = self.embedding_generator.generate_embedding(image)
        image.embedding = embedding_obj.vector
        
        # Clasificar
        label = self.classifier.predict(image)
        probabilities = self.classifier.get_cluster_probabilities(image)
        
        return {
            'image_path': str(image_path),
            'image_name': image_path.name,
            'predicted_label': label.name,
            'confidence': label.confidence,
            'cluster_probabilities': probabilities,
            'metadata': label.metadata
        }
    
    def get_pipeline_summary(self) -> Dict[str, Any]:
        """
        Obtiene un resumen del estado del pipeline.
        
        Returns:
            Diccionario con informaci√≥n del pipeline
        """
        summary = {
            'is_trained': self.is_trained,
            'execution_stats': self.execution_stats.copy(),
            'components': {
                'embedding_generator': self.embedding_generator.get_model_info(),
                'clusterer': self.clusterer.get_cluster_info(),
                'clip_labeler': self.clip_labeler.get_model_info(),
                'classifier': self.classifier.get_classifier_info()
            }
        }
        
        if self.current_dataset:
            summary['dataset_info'] = {
                'name': self.current_dataset.name,
                'total_images': self.current_dataset.size,
                'labeled_images': self.current_dataset.num_labeled_images,
                'num_clusters': self.current_dataset.num_clusters
            }
        
        if self.trained_clusters:
            summary['cluster_info'] = {
                'total_clusters': len(self.trained_clusters),
                'cluster_labels': [(c.id, c.label, c.size) for c in self.trained_clusters],
                'avg_cluster_size': sum(c.size for c in self.trained_clusters) / len(self.trained_clusters)
            }
        
        return summary
    
    def save_trained_model(self, model_path: Path) -> None:
        """
        Guarda el modelo entrenado.
        
        Args:
            model_path: Ruta donde guardar el modelo
        """
        if not self.is_trained:
            raise RuntimeError("No hay modelo entrenado para guardar")
        
        # TODO: Implementar guardado del modelo completo
        # Incluir√≠a clusters, embeddings, configuraciones, etc.
        print(f"üíæ Guardando modelo en: {model_path}")
    
    def load_trained_model(self, model_path: Path) -> None:
        """
        Carga un modelo previamente entrenado.
        
        Args:
            model_path: Ruta del modelo guardado
        """
        # TODO: Implementar carga del modelo completo
        print(f"üìÇ Cargando modelo desde: {model_path}")
    
    def visualize_clusters(self) -> Dict[str, Any]:
        """
        Genera datos para visualizar los clusters.
        
        Returns:
            Diccionario con datos de visualizaci√≥n
        """
        if not self.trained_clusters:
            return {'error': 'No hay clusters entrenados'}
        
        # TODO: Implementar generaci√≥n de datos para visualizaci√≥n
        # Podr√≠a incluir reducci√≥n dimensional (PCA, t-SNE) para graficar
        
        visualization_data = {
            'clusters': [],
            'total_clusters': len(self.trained_clusters),
            'total_images': sum(c.size for c in self.trained_clusters)
        }
        
        for cluster in self.trained_clusters:
            cluster_data = {
                'id': cluster.id,
                'label': cluster.label,
                'size': cluster.size,
                'confidence': cluster.confidence,
                'representative_images': [str(img.path) for img in cluster.representative_images]
            }
            visualization_data['clusters'].append(cluster_data)
        
        return visualization_data